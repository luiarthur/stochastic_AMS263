{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open in [nbviewer](http://nbviewer.jupyter.org/github/luiarthur/stochastic_AMS263/blob/master/hw/hw1/hw1.ipynb)\n",
    "$\n",
    "% Latex definitions\n",
    "% note: Ctrl-shfit-p for shortcuts menu\n",
    "\\newcommand{\\iid}{\\overset{iid}{\\sim}}\n",
    "\\newcommand{\\ind}{\\overset{ind}{\\sim}}\n",
    "\\newcommand{\\p}[1]{\\left(#1\\right)}\n",
    "\\newcommand{\\bk}[1]{\\left[#1\\right]}\n",
    "\\newcommand{\\bc}[1]{ \\left\\{#1\\right\\} }\n",
    "\\newcommand{\\abs}[1]{ \\left|#1\\right| }\n",
    "\\newcommand{\\norm}[1]{ \\left|\\left|#1\\right|\\right| }\n",
    "\\newcommand{\\E}{ \\text{E} }\n",
    "\\newcommand{\\N}{ \\mathcal N }\n",
    "\\newcommand{\\ds}{ \\displaystyle }\n",
    "\\newcommand{\\R}{ \\mathbb{R} }\n",
    "\\newcommand{\\suml}{ \\sum_{i=1}^n }\n",
    "\\newcommand{\\prodl}{ \\prod_{i=1}^n }\n",
    "\\newcommand{\\overunderset}[3]{\\overset{#1}{\\underset{#2}{#3}}}\n",
    "\\newcommand{\\asym}{\\overset{\\cdot}{\\sim}}\n",
    "\\newcommand{\\given}{\\bigg |}\n",
    "\\newcommand{\\M}{\\mathcal{M}}\n",
    "\\newcommand{\\Mult}{\\text{Mult}}\n",
    "\\newcommand{\\F}{\\mathcal{F}}\n",
    "\\newcommand{\\P}{\\mathcal{P}}\n",
    "\\newcommand{\\Var}{\\text{Var}}\n",
    "\\newcommand{\\Cov}{\\text{Cov}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1  \n",
    "$\\newcommand{\\sumk}{\\sum_{l=1}^k}$\n",
    "$\\newcommand{\\Xti}{X_{t_i}}$\n",
    "$\\newcommand{\\Xtj}{X_{t_j}}$\n",
    "**Consider real-valued random variables $A_i,B_i$, where $i=1,...,k$, such that $\\E(A_i)=\\E(B_i)=0$ and\n",
    "Var($A_i$) =Var($B_i$) = $\\sigma^2>0$, for $i=1,...,k$. Moreover, assume they are mutually uncorrelated, that is, \n",
    "$\\E(A_i,A_j) = \\E(B_iB_j) = 0$ for $i\\ne j$, and $\\E(A_iB_j) = 0$ for all $i,j$. Define the stochastic process \n",
    "$X = \\bc{X_t: t\\in \\mathbb R}$ by $X_t = \\sumk A_i \\cos(\\omega_i t) + B_i \\sin(\\omega_i t)$, where $\\omega_i$\n",
    "are real constants $i=1,...,k$. Show that $X$ is weakly stationary. **\n",
    "\n",
    "***\n",
    "\n",
    "Recall that a stochastic process is weakly stationary if \n",
    "1. $\\E\\bk{X_t} = \\mu$, and\n",
    "2. $\\forall t_i,t_j \\in T$, $Cov(X_{t_i},X_{t_j})=c(t_i-t_j)$, which is a function of only $t_i-t_j$.\n",
    "\n",
    "\n",
    "Now note that:\n",
    "\n",
    "\\begin{split}\n",
    "\\E\\bk{X_t} &= \\E\\bk{\\sumk A_l \\cos(\\omega_l t) + B_l \\sin(\\omega_l t)} \\\\\n",
    "           &= \\sumk \\E\\bk{A_l} \\cos(\\omega_l t) + \\E\\bk{B_l} \\sin(\\omega_l t) \\\\\n",
    "           &= 0, \\text{ a constant}\n",
    "\\end{split}\n",
    "\n",
    "So, 1 is true. We now need to show that the $Cov(X_{t_i},X_{t_j})$ is a function of only $t_i-t_j$.\n",
    "\n",
    "\\begin{split}\n",
    "Cov(\\Xti, Xtj) &= \\E\\bk{\\Xti\\Xtj} - \\E\\bk{\\Xti}\\E\\bk{\\Xtj} \\\\\n",
    "               &= \\E\\bk{\\Xti\\Xtj} - 0 \\\\\n",
    "               &= \\E\\bk{\\bc{\\sumk A_l\\cos(\\omega_l t_i) + B_l\\sin(\\omega_l t_i)} \\times \n",
    "                        \\bc{\\sumk A_l\\cos(\\omega_l t_j) + B_l\\sin(\\omega_l t_j)}} \\\\\n",
    "               &= \\E\\bk{\\sumk\\bc{A_l\\cos(\\omega_l t_i) + B_l\\sin(\\omega_l t_i)}\\times\n",
    "                             \\bc{A_l\\cos(\\omega_l t_j) + B_l\\sin(\\omega_l t_j)} } + 0 \\\\\n",
    "               &= \\E\\bk{\\sumk A_l^2 \\cos(\\omega_l t_i)\\cos(\\omega_l t_j) +  \n",
    "                              B_l^2 \\sin(\\omega_l t_i)\\sin(\\omega_l t_j) +\n",
    "                              A_l B_l(\\sin(\\omega_l t_i)\\cos(\\omega_l t_j) + \\cos(\\omega_l t_i)\\sin(\\omega_l t_j))} \\\\\n",
    "               &= \\sumk\\bc{\\E\\bk{A_l^2}\\cos(\\omega_l t_i)\\cos(\\omega_l t_j) + \n",
    "                           \\E\\bk{B_l^2}\\sin(\\omega_l t_i)\\sin(\\omega_l t_j) + 0} \\\\\n",
    "               &= \\sumk\\bc{(Var\\bk{A_l^2}+0)\\cos(\\omega_l t_i)\\cos(\\omega_l t_j) + \n",
    "                           (Var\\bk{B_l^2}+0)\\sin(\\omega_l t_i)\\sin(\\omega_l t_j)} \\\\\n",
    "               &= \\sumk\\sigma_l^2\\bc{\\cos(\\omega_l t_i)\\cos(\\omega_l t_j) + \n",
    "                                     \\sin(\\omega_l t_i)\\sin(\\omega_l t_j)} \\\\                          \n",
    "               &= \\sumk\\sigma_l^2\\bc{\\cos(~\\omega_l(t_i-t_j)~)}, \\text{ which is a function of only $t_i-t_j$.}\\\\\n",
    "\\end{split}\n",
    "\n",
    "Therefore, $X$ is a weakly stationary process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2\n",
    "\n",
    "**Consider a discrete-time, real-valued stochastic process $X=\\bc{X_n: n\\in \\mathbb{N}}$ defined by\n",
    "$X_n = \\cos(nU)$, where $U$ is distributed Uniform($-\\pi,\\pi$). Show that $X$ is weakly stationary but not\n",
    "strongly stationary. **\n",
    "\n",
    "***\n",
    "\n",
    "\\begin{split}\n",
    "X_n &= \\cos(nU) \\\\\n",
    "\\\\\n",
    "f_{X_n}(x_n) &= f_U(\\cos^{-1}(x_n) / n ) \\abs{\\frac{d}{dx_n} \\frac{\\cos^{-1}(x_n)}{n}} \\\\\n",
    "&= \\frac{1}{2\\pi} \\frac{1}{n\\sqrt{1-x_n^2}} \\\\\n",
    "&= \\frac{1}{2\\pi n\\sqrt{1-x_n^2}} \\\\\n",
    "\\\\\n",
    "\\E\\bk{X_n} &= \\int_{-1}^1 x_n f_{x_n}(x_n) dx_n \\\\\n",
    "\\end{split}\n",
    "\n",
    "By letting $x_n = \\cos y_n$, we easily solve the expected value required to be 0. \n",
    "\n",
    "\\begin{split}\n",
    "Cov(X_i,X_j) &= \\E\\bk{X_i X_j} - \\E\\bk{X_i}\\E\\bk{X_j} \\\\\n",
    "             &= \\E\\bk{X_i X_j} - 0 \\\\\n",
    "             &= \\E\\bk{\\cos(iU) \\cos(jU)} \\\\\n",
    "             &= \\frac{1}{2} \\E\\bk{\\cos(iU + jU) + \\cos(iU - jU)} \\\\\n",
    "             &= \\frac{1}{2} \\E\\bk{\\cos(\\bk{i+j}U) + \\cos(\\bk{i-j}U)} \\\\\n",
    "             &= \\frac{1}{2} \\bc{\\E\\bk{\\cos(\\bk{i+j}U)} + \\E\\bk{\\cos(\\bk{i-j}U)}} \\\\\n",
    "             &= \\frac{1}{2} \\bc{0 + \\E\\bk{\\cos(\\bk{i-j}U)}} \\\\\n",
    "\\end{split}\n",
    "\n",
    "which is a function of only $i-j$. Note also, that the $\\E\\bk{\\cos(\\bk{i-j}U)}$ is simply $1$ if $i=j$ and 0 otherwise. Therefore, the covariance is $\\frac{1}{2}$ if $j=i$ and 0 otherwise.\n",
    "\n",
    "To show that $X$ is not SS, consider $X_1=cos(u), X_2=cos(2u)$. Clearly, they do not have the same distributions.\n",
    "Therefore, $X$ is not SS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 \n",
    "** Consider a weakly stationary process $X=\\bc{X_t: t\\in\\mathbb{R}}$ with zero mean and unit variance. Find the covariance function of $X$ if the spectral density function $f$  of $X$ is given by: **\n",
    "1. $f(u) = 0.5\\exp(-\\abs{u})$\n",
    "2. $f(u) = \\phi (\\alpha^2 + u^2)^{-1}$\n",
    "3. $f(u) = 0.5\\sigma(\\pi\\alpha)^{-1}\\exp(-u^2/(4\\alpha))$\n",
    "\n",
    "**where in each case, $u \\in \\mathbb{R}$.**\n",
    "\n",
    "---\n",
    "\n",
    "Recall that the autocovariance for a WS SP with strictly positive variance is \n",
    "$c(t) = \\int_{-\\infty}^\\infty ~\\exp(iut)f(u)~ du$.\n",
    "\n",
    "\n",
    "### 3.1\n",
    "\\begin{split}\n",
    "f(u) &= 0.5\\exp(-\\abs{u}) \\\\\n",
    "\\\\\n",
    "c(t) &= \\int_{-\\infty}^\\infty ~\\exp(iut)f(u)~ du \\\\\n",
    "&= \\int_{-\\infty}^\\infty ~\\exp(iut)~0.5\\exp(-\\abs{u})~ du \\\\\n",
    "&= \\frac{1}{2}\\int_{-\\infty}^\\infty ~\\exp(iut-\\abs{u})~ du \\\\\n",
    "&= \\frac{1}{2}\\bc{\\int_{-\\infty}^0 ~\\exp(iut+u)~ du + \\int_0^\\infty ~\\exp(iut-u)~ du} \\\\\n",
    "&= \\frac{1}{2}\\bc{\\frac{\\exp\\bk{(it+1)u}}{it+1} \\bigg|_{-\\infty}^0 + \\frac{\\exp\\bk{(it-1)u}}{it-1}\\bigg|_0^\\infty} \\\\\n",
    "&= \\frac{1}{2}\\bc{\\frac{1}{it+1} -0 + \\frac{e^{itu}e^{-u}}{it-1}\\bigg|_0^\\infty} \\\\\n",
    "&= \\frac{1}{2}\\bc{\\frac{1}{it+1} + \\frac{\\bk{\\cos(tu)+i\\sin(tu)}e^{-u}}{it-1}\\bigg|_0^\\infty} \\\\\n",
    "&= \\frac{1}{2}\\bc{\\frac{1}{it+1} + \\frac{0-1}{it-1}} \\\\\n",
    "&= \\frac{1}{2}\\bc{\\frac{1}{it+1} - \\frac{1}{it-1}} \\\\\n",
    "&= \\frac{1}{t^2+1}\n",
    "\\end{split}\n",
    "\n",
    "### 3.2 (IDK...)\n",
    "\n",
    "### 3.3\n",
    "\\begin{split}\n",
    "f(u) &= \\frac{\\sigma}{2\\pi\\alpha} \\exp(-u^2/(4\\alpha)) \\\\\n",
    "\\\\\n",
    "c(t) &= \\int_{-\\infty}^\\infty ~ \\exp(iut)~f(u)~du \\\\\n",
    "&= \\int_{-\\infty}^\\infty ~ \\exp(iut)~ \\frac{\\sigma}{2\\pi\\alpha} \\exp(-u^2/(4\\alpha)) ~du \\\\\n",
    "&= \\frac{\\sigma}{2\\pi\\alpha} \\int_{-\\infty}^\\infty ~ \\exp(iut)~ \\exp(-u^2/(4\\alpha)) ~du \\\\\n",
    "&= \\frac{\\sigma}{2\\pi\\alpha} \\int_{-\\infty}^\\infty ~ \\exp\\p{iut - \\frac{u^2}{4\\alpha}} ~du \\\\\n",
    "&= \\frac{\\sigma}{2\\pi\\alpha} \\int_{-\\infty}^\\infty ~ \\exp\\p{\\frac{-u^2}{2(2\\alpha)} + \\frac{2(2it\\alpha)u}{2(2\\alpha)}} ~du \\\\\n",
    "&= \\frac{\\sigma}{2\\pi\\alpha} \\int_{-\\infty}^\\infty ~ \\exp\\p{\\frac{-(u-2it\\alpha)^2}{2(2\\alpha)}} ~du \n",
    "\\times\\exp\\p{\\frac{(2it\\alpha)^2}{4\\alpha}}\\\\\n",
    "&= \\frac{\\sigma}{2\\pi\\alpha} \\sqrt{2\\pi(2\\alpha)} \\exp\\p{-t^2\\alpha}\\\\\n",
    "&= \\frac{\\sigma}{\\sqrt{\\pi\\alpha}}\\exp\\p{-t^2\\alpha}\\\\\n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4\n",
    "**Show that strong and weak stationarity are equivalent for a Gaussian Process.**\n",
    "\n",
    "---\n",
    "\n",
    "Recall that a GP is a SP for which any finite-dimensional distribution (fdd) is Normal. i.e., \n",
    "$\\bc{X_t: t\\in\\mathbb{R}}$ is a GP for any $t_1,...,t_n$ where $n\\in mathbb{N}$. s.t.\n",
    "$(x_{t_1},...,x_{t_n})$ is multivariate normal.\n",
    "\n",
    "To show for a GP WS iff SS, we need to show that (1) WS $\\Rightarrow$ SS and (2) SS $\\Rightarrow$ WS.\n",
    "\n",
    "We first show the first direction is true (WS $\\Rightarrow$ SS):\n",
    "\n",
    "If GP is WS, then $E(X_t) = \\mu$ and $Cov(X_{t_i},X_{t_j}) = c(t_i-t_j)$.\n",
    "\n",
    "So, $(x_{t_1},...,x_{t_n})$ is multivariate Normal with a constant mean vector $\\mu \\mathbf 1_n$\n",
    "and covariance matrix $K$ where $K_{i,j} = c(t_i-t_j)$.\n",
    "\n",
    "But, $(x_{t_1+h},...,x_{t_n+h})$ is also multivariate Normal with a constant mean vector $\\mu \\mathbf 1_n$\n",
    "and covariance matrix $K$ where $K_{i,j} = c((t_i+h)-(t_j+h)) = c(t_i - t_j))$.\n",
    "\n",
    "Since a multivariate Normal distribution is fully specified by its first two moments and we have shown that \n",
    "for any $h$, $(x_{t_1+h},...,x_{t_n+h})$ has the same distribution, for a GP, WS implies SS.\n",
    "\n",
    "To show the opposite direction (SS $\\Rightarrow$ WS),\n",
    "\n",
    "Note that $(x_{t_1},...,x_{t_n})$ and $(x_{t_1+h},...,x_{t_n+h})$ have the same distribution.\n",
    "\n",
    "So, $\\E(X_t) = \\E(X_{t_h}) \\Rightarrow \\E(X_t) = \\mu$. \n",
    "\n",
    "Also, $\\Cov(X_{t_i},X_{t_j}) = \\Cov(X_{t_i+h},X_{t_j+h})$. Consequently, $K_{i,j} = K'_{i+h,j+h} = K_{i+h,j+h}$.\n",
    "This also means that $K_{i,j} = K_{i+h,j+h}$.\n",
    "\n",
    "Since $h$ is arbitrary, $K_{i,j}$ is only a function of $i-j$.\n",
    "\n",
    "Therefore, SS $\\Rightarrow$ WS also.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5\n",
    "**By definition, a continuous-time, real-valued stochastic process $X=\\bc{X_t: t\\in\\mathbb{R}}$ is called a \n",
    "Markov process if for all $n$, for all $x=x_1,...,x_n$, and all increasing sequences, $t_1,...,t_n$ of index\n",
    "points,** \n",
    "\n",
    "$$P(X_{t_n}\\le x ~|~ X_{t_1}=x_1,...,  X_{t_n}=x_n) = P(X_{t_n}\\le x ~|~ X_{t_n}=x_n)$$\n",
    "\n",
    "**Let $Z$ be a real-valued GP. Show that $Z$ is a Markov process (MP) iff $\\E(X_{t_n} ~|~ X_{t_1}=x_1,...,  X_{t_n}=x_n) = \\E(X_{t_n} ~|~ X_{t_n}=x_n)$.**\n",
    "\n",
    "---\n",
    "\n",
    "$\\newcommand{\\eqa}{E(X_{t_n} ~|~ X_{t_1}=x_1,...,  X_{t_{n-1}}=x_{n-1}) = E(X_{t_n} ~|~ X_{t_{n-1}}=x_{n-1})}$\n",
    "$\\newcommand{\\eqb}{P(X_{t_n}\\le x ~|~ X_{t_1}=x_1,...,  X_{t_{n-1}}=x_{n-1}) = P(X_{t_n}\\le x ~|~ X_{t_{n-1}}=x_{n-1})}$\n",
    "\n",
    "We need to show that  $Z$ is MP $\\iff$ $\\eqa$.\n",
    "\n",
    "For the first direction, note that $Z$ is an MP $\\Rightarrow\\eqb\\Rightarrow$ \n",
    "the conditional CDF's are the same. So, $\\eqa$. That is, since the conditional CDF's are the same, the conditional\n",
    "distributions are the same. So, the conditional expectations are the same.\n",
    "\n",
    "For the opposite direction,\n",
    "\n",
    "In order to show that $\\eqb$ is true, we need only show that the first and second moments are equal. Since\n",
    "it is given that the first moments are equal, we need only show that the second moments (or covariance matrices) are equal.\n",
    "\n",
    "Let $\\Sigma_{12} = \\Cov(X_{t_n},X_{t_{-n}})$.\n",
    "Let $\\Sigma_{22} = \\Var(X_{t_{-n}})$.\n",
    "Let $\\Sigma_{11} = \\Var(X_{t_n})$.\n",
    "\n",
    "Let $\\sigma_{12} = \\Cov(X_{t_n},X_{t_{n-1}})$.\n",
    "Let $\\sigma_{22} = \\Var(X_{t_{n-1}})$.\n",
    "Let $\\sigma_{11} = \\Var(X_{t_n})$.\n",
    "\n",
    "\\begin{split}\n",
    "&\\eqa \\\\\n",
    "\\Rightarrow & \\mu_{n} + \\Sigma_{12}\\Sigma_{22}^{-1}(x_{1:n-1} - \\mu_{1:n-1}) =\n",
    "\\mu_{n} + \\sigma_{11}\\sigma_{22}^{-1}(x_{n-1} - \\mu_{n-1}) \\\\\n",
    "\\Rightarrow & \\Var(\\mu_{n} + \\Sigma_{12}\\Sigma_{22}^{-1}(x_{1:n-1} - \\mu_{1:n-1})) =\n",
    "\\Var(\\mu_{n} + \\sigma_{12}\\sigma_{22}^{-1}(x_{n-1} - \\mu_{n-1})) \\\\\n",
    "\\Rightarrow & \\Var(\\Sigma_{12}\\Sigma_{22}^{-1}(x_{1:n-1} - \\mu_{1:n-1})) =\n",
    "\\Var(\\sigma_{12}\\sigma_{22}^{-1}(x_{n-1} - \\mu_{n-1})) \\\\\n",
    "\\Rightarrow & \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{22}\\Sigma_{22}^{-1}\\Sigma_{21}=\n",
    "\\sigma_{12}\\sigma_{22}^{-1}\\sigma_{22}\\sigma_{22}^{-1}\\sigma_{21} \\\\\n",
    "\\Rightarrow & \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}=\n",
    "\\sigma_{12}\\sigma_{22}^{-1}\\sigma_{21} \\\\\n",
    "\\Rightarrow & \\sigma_{11} - \\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}=\n",
    "\\sigma_{11} - \\sigma_{12}\\sigma_{22}^{-1}\\sigma_{21} \\\\\n",
    "\\Rightarrow& \\Var(Z_n|Z_{-n}) = \\Var(Z_n|Z_{n-1}). \\\\\n",
    "\\end{split}\n",
    "\n",
    "Therefore, $Z$ is MP $\\iff$ $\\eqa$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6\n",
    "**Show that any stochastic process $X=\\bc{X_n: n=0,...}$ with independent increments is a Markov process.**\n",
    "\n",
    "http://statweb.stanford.edu/~adembo/math-136/Markov_note.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7\n",
    "**Let $W=\\bc{W_t:t\\ge 0}$ is a Brownian motion. Show that a Brownian motion can be viewed as a GP with\n",
    "mean 0 and Cov($W_s,W_t$) = min$\\bc{s,t}$.**\n",
    "\n",
    "---\n",
    "\n",
    "A GP is a SP where any fdd is Normal. i.e., $\\bc{X_t: t\\in \\mathbb{R}}$ is a GP if for any $t_1,...,t_n$, $n\\in\\mathbb{N}$, $(X_{t_1},...,X_{t_n}) \\sim MVN(\\cdot,\\cdot)$.\n",
    "\n",
    "In a Brownian motion, $(B_{t_1},...,B_{t_n}) \\sim MVN(0,\\Sigma)$, where  $\\Sigma_{s,t} = \\text{min}(s,t)$.\n",
    "This is clearly a special case of the GP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8\n",
    "**Show that for a Brownian motion $\\E\\bk{\\abs{W_s-Wt}^{2n}} = \\ds\\frac{(2n)!}{2^n n!}\\abs{s-t}^n $.**\n",
    "\n",
    "---\n",
    "\n",
    "Let $Y = W_s-W_t$. Then $Y \\sim N(0,s-t)$.\n",
    "\n",
    "Let $Z = \\ds\\frac{Y}{\\sqrt{s-t}}$. Then $Z \\sim N(0,1)$.\n",
    "\n",
    "Finally, let $X = Z^2$. Then $X \\sim \\chi^2(1)$.\n",
    "\n",
    "So, \n",
    "\\begin{split}\n",
    " & \\E\\bk{\\abs{W_s-Wt}^{2n}} \\\\\n",
    "=& \\E\\bk{\\abs{Y}^{2n}} \\\\\n",
    "=& \\E\\bk{\\abs{Z\\sqrt{s-t}}^{2n}} \\\\\n",
    "=& \\abs{s-t}^n\\E\\bk{\\abs{Z}^{2n}} \\\\\n",
    "=& \\abs{s-t}^n\\E\\bk{Z^{2n}} \\\\\n",
    "=& \\abs{s-t}^n\\E\\bk{X^n} \\\\\n",
    "\\end{split}\n",
    "\n",
    "Note that the MGF $M_x(t)$ of a $\\chi^2(k)$ random variable is $(1-2t)^{-k/2}$ for $t<1/2$. \n",
    "So, $\\E\\bk{X^n} = M_x^{(n)}(0)$. The MGF can be obtained as follows:\n",
    "\n",
    "\\begin{split}\n",
    "M_x^{(1)}(t) &= 1(1-2t)^{\\frac{1}{2}-1}\\\\\n",
    "M_x^{(2)}(t) &= 1\\times 3(1-2t)^{\\frac{1}{2}-2}\\\\\n",
    "M_x^{(3)}(t) &= 1\\times 3 \\times 5(1-2t)^{\\frac{1}{2}-3}\\\\\n",
    "\\vdots \\\\\n",
    "M_x^{(n)}(t) &= \\bc{\\prod_{j=1}^n 2j-1} (1-2t)^{\\frac{1}{2}-n}\\\\\n",
    "\\end{split}\n",
    "\n",
    "Therefore, \n",
    "\\begin{split}\n",
    "\\E\\bk{X^n} = M_x^{(n)}(0) = \\prod_{j=1}^n 2j-1 &= 1 \\times 3 \\times ... \\times (2n-1) \\\\\n",
    "&= \\ds\\frac{1 \\times 2 \\times ... \\times (2n)}{2\\times4\\times...\\times(2n)} \\\\\n",
    "&= \\ds\\frac{(2n)!}{(2\\times 1) \\times (2\\times2) \\times ...\\times (2\\times n)} \\\\\n",
    "&= \\ds\\frac{(2n)!}{2^n n!} \\\\\n",
    "\\end{split}\n",
    "\n",
    "Therefore, \n",
    "$\\E\\bk{\\abs{W_s-Wt}^{2n}} = \\abs{s-t}^n\\E\\bk{X^n} = \\abs{s-t}^n\\ds\\frac{(2n)!}{2^n n!}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
