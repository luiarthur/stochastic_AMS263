{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open in [nbviewer](http://nbviewer.jupyter.org/github/luiarthur/stochastic_AMS263/blob/master/notes/notes2.ipynb)\n",
    "$\n",
    "% Latex definitions\n",
    "% note: Ctrl-shfit-p for shortcuts menu\n",
    "\\newcommand{\\iid}{\\overset{iid}{\\sim}}\n",
    "\\newcommand{\\ind}{\\overset{ind}{\\sim}}\n",
    "\\newcommand{\\p}[1]{\\left(#1\\right)}\n",
    "\\newcommand{\\bk}[1]{\\left[#1\\right]}\n",
    "\\newcommand{\\bc}[1]{ \\left\\{#1\\right\\} }\n",
    "\\newcommand{\\abs}[1]{ \\left|#1\\right| }\n",
    "\\newcommand{\\ceil}[1]{ \\lceil#1\\rceil }\n",
    "\\newcommand{\\norm}[1]{ \\left|\\left|#1\\right|\\right| }\n",
    "\\newcommand{\\E}{ \\text{E} }\n",
    "\\newcommand{\\N}{ \\mathcal N }\n",
    "\\newcommand{\\ds}{ \\displaystyle }\n",
    "\\newcommand{\\R}{ \\mathbb{R} }\n",
    "\\newcommand{\\suml}{ \\sum_{i=1}^n }\n",
    "\\newcommand{\\prodl}{ \\prod_{i=1}^n }\n",
    "\\newcommand{\\overunderset}[3]{\\overset{#1}{\\underset{#2}{#3}}}\n",
    "\\newcommand{\\asym}{\\overset{\\cdot}{\\sim}}\n",
    "\\newcommand{\\given}{\\bigg |}\n",
    "\\newcommand{\\M}{\\mathcal{M}}\n",
    "\\newcommand{\\Mult}{\\text{Mult}}\n",
    "\\newcommand{\\F}{\\mathcal{F}}\n",
    "\\newcommand{\\P}{\\mathcal{P}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models\n",
    "Observation $Y_n$ for $n=0,1,...$ are generated from a conditional distribution $f(y_n|x_n)$ with parameters depending on an unnobserved or hidden state, $x_n \\in \\bc{1,2,...,K}$. Hidden states follow a transition matrix $P$.\n",
    "\n",
    "## Partially Observed Data: Inference Example\n",
    "Let the data be observed at time $t_1, t_6, t_9,t_{20},t_{35}$. Let the transition matrix be fiven by $P = \\p{p_{ij}}_{i,j=1}^m$.\n",
    "\n",
    "If the all observations were present, $\\prod_{i,j}^m p_{ij}^{n_{ij}}$. $n_{ij}$ is the number of transitions from i to j.\n",
    "\n",
    "Let $x_0$ be the known initial state and we observe $X_0=(x_{n_1},...,x_{n_m})$ where $n_1 < ... < n_m \\in \\mathbb{N}$.\n",
    "\n",
    "$$\n",
    "L(p|x_0) = \\prod_{i=1}^m p_{n_{i-1},n_i}^{t_i-t_{i-1}}\n",
    "$$\n",
    "\n",
    "where $p_{ij}^{(t)}$ is the (i,j)-th entry of $t$ step transition matrix. i.e. $P^t$.\n",
    "\n",
    "## Hidden Markov Model (HMM)\n",
    "An HMM is based upon unobserved finite state RVs $S_t \\in \\bc{1,...,m}$ which evolve according to a markov chain. i.e. \n",
    "\n",
    "$$ P(S_t=j \\mid S_{t-1}=i) = p_{ij} $$\n",
    "\n",
    "where $\\p{p_{ij}}_{i,j=1}^m$ is a transition matrix . \n",
    "\n",
    "Let $\\pi_1$ be the probability distribution of $S_1$.\n",
    "\n",
    "Assume that the chain is irreducible, aperiodic and time homogeneous. These are required for identifiability.\n",
    "\n",
    "At each observation point $t$, a realization of the state occurs. Given $S_t=k$, $y_t$ is drawn as follows:\n",
    "\n",
    "$$ y_t \\mid y_{t-1},\\theta_k \\sim f(y_t\\mid y_{t-1},\\theta_k) $$\n",
    "\n",
    "where $y_{t-1} = (y_1,...,y{t-1})$ and $k=1,...,m$.\n",
    "\n",
    "This implies that\n",
    "\n",
    "$$\n",
    "f(y_t|y_{t-1},s_{t-1},\\theta) = \n",
    "\\begin{cases}\n",
    "\\sum_{k=1}^m f(y_t \\mid y_{t-1},\\theta_k) \\pi_1(s_t=k), & t=1 \\\\\n",
    "\\sum_{k=1}^m f(y_t \\mid y_{t-1},\\theta_k) P(s_t=k|s_{t-1}), & t\\ge 2 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{\\theta} = (\\theta_1,...,\\theta_m, p_{ij}, i,j,=1,...,m)$.\n",
    "\n",
    "This is very different from the mixture model. In a mixture model, component specific latent variables are generally independent. In HMM, there is a serial correlation b/w them.\n",
    "\n",
    "This representation is computationally cumbersome. So, we use $s_1,...,s_n$ as latent parameters and sample them alongside.\n",
    "\n",
    "Good paper to read: **[Chib (1996) HMM](../resources/chib1996.pdf)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Define: $S_t = (s_1,...,s_t)$,  $S^{t+1} = (s_{t+1},...s_n)$. Similarly, $Y_t=(y_1,...,y_t)$ and $Y^{t+1}=(y_{t+1},...,y_n)$.\n",
    "\n",
    "$$P(S_n \\mid Y_n, \\theta) = p(s_n\\mid Y_n,\\theta) \\times ... \\times p(s_t\\mid Y_n,S^{t+1},\\theta) \\times p(s_1\\mid Y_n,S^2,\\theta)$$\n",
    "\n",
    "$p(s_t \\mid Y_n, S^{t+1},\\theta)$ is a typical term in this product.\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "p(s_t \\mid Y_n, S^{t+1},\\theta) &\\propto p(s_t \\mid Y_t, \\theta) ~g(Y^{t+1},S^{t+1}\\mid Y_t,s_t,\\theta) \\\\\n",
    "&\\propto p(s_t \\mid Y_t, \\theta)~ p(s_{t+1}\\mid s_t,\\theta) ~g(Y^{t+1},S^{t+2}\\mid Y_t,s_t,s_{t+1},\\theta) \\\\\n",
    "\\\\\n",
    "\\Rightarrow p(s_t \\mid Y_n, S^{t+1},\\theta) &\\propto p(s_t \\mid Y_t, \\theta)~ p(s_{t+1}\\mid s_t,\\theta)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "The last step follows because $Y^{t+1},S^{t+1}|s_{t+1}$ is independent of $s_t$ by the Markov property.\n",
    "\n",
    "Thus the mass function of $s_t$ is proportional to the product of two terms, one of which is the mass function of $s_t$ given $(Y_t,\\theta)$ and the other is the transition prob given $\\theta$.\n",
    "\n",
    "Assume $p(s_{t-1}\\mid Y_{t-1},\\theta)$ is available, then repeat the following steps:\n",
    "\n",
    "### Prediction step\n",
    "$$ p(s_t|Y_{t-1},\\theta) = \\sum_{k=1}^m p(s_t|s_{t-1}=k,\\theta) p(s_{t-1}=k|Y_{t-1},\\theta)$$\n",
    "\n",
    "### UPdate step\n",
    "$$ p(s_t|Y_{t},\\theta) \\propto p(s_t|Y_{t-1}=k,\\theta) f(y_{t}|Y_{t-1},\\theta)$$\n",
    "\n",
    "\n",
    "### Algorithm\n",
    "Initialize at $t=1$ by setting $p(s_1|y_0,\\theta)$ to be the stationary distribution of the chain.\n",
    "\n",
    "Run the prediction and update steps recursively ro comp[ute the mass fn of $p(s_t|Y_t,\\theta)$. \n",
    "\n",
    "$S_n$ is the first updated Then the remaining steps are simulated from equation (1) above...\n",
    "\n",
    "We know how to draw samples from $s_1,...,s_n$. \n",
    "\n",
    "### p-update\n",
    "WE use $p_i=(p_{i1},...,p_{im})\\sim Dir(\\alpha_{i1},...,alpha_{im})$ then $p_i mid s_n \\sim Dir(\\alpha_{i1}+n_{i1},...,\\alpha_{im}+n_{im})$, where $n_{ik}$ = the total number of transitions $i$ to $k$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Example in Chib 1996 Section 4.1\n",
    "\n",
    "Infact, just refer to the paper for this lecture on HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
