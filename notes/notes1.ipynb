{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open in [nbviewer](http://nbviewer.jupyter.org/github/luiarthur/stochastic_AMS263/blob/master/notes/notes1.ipynb)\n",
    "$\n",
    "% Latex definitions\n",
    "% note: Ctrl-shfit-p for shortcuts menu\n",
    "\\newcommand{\\iid}{\\overset{iid}{\\sim}}\n",
    "\\newcommand{\\ind}{\\overset{ind}{\\sim}}\n",
    "\\newcommand{\\p}[1]{\\left(#1\\right)}\n",
    "\\newcommand{\\bk}[1]{\\left[#1\\right]}\n",
    "\\newcommand{\\bc}[1]{ \\left\\{#1\\right\\} }\n",
    "\\newcommand{\\abs}[1]{ \\left|#1\\right| }\n",
    "\\newcommand{\\ceil}[1]{ \\lceil#1\\rceil }\n",
    "\\newcommand{\\norm}[1]{ \\left|\\left|#1\\right|\\right| }\n",
    "\\newcommand{\\E}{ \\text{E} }\n",
    "\\newcommand{\\N}{ \\mathcal N }\n",
    "\\newcommand{\\ds}{ \\displaystyle }\n",
    "\\newcommand{\\R}{ \\mathbb{R} }\n",
    "\\newcommand{\\suml}{ \\sum_{i=1}^n }\n",
    "\\newcommand{\\prodl}{ \\prod_{i=1}^n }\n",
    "\\newcommand{\\overunderset}[3]{\\overset{#1}{\\underset{#2}{#3}}}\n",
    "\\newcommand{\\asym}{\\overset{\\cdot}{\\sim}}\n",
    "\\newcommand{\\given}{\\bigg |}\n",
    "\\newcommand{\\M}{\\mathcal{M}}\n",
    "\\newcommand{\\Mult}{\\text{Mult}}\n",
    "\\newcommand{\\F}{\\mathcal{F}}\n",
    "\\newcommand{\\P}{\\mathcal{P}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Overview\n",
    "- Office hours: Th 3-4pm (or by appointment)\n",
    "\n",
    "# Course Description\n",
    "- definitions and properties of stochastic proc\n",
    "- some important stoc. proc.\n",
    "- discrete / cont. time and space stoc proc\n",
    "- hidden markov models\n",
    "- markes poisson poisson process\n",
    "- more involved study of GP\n",
    "\n",
    "# HW (not collected)\n",
    "- 5 assignments\n",
    "- 5-6 full computational\n",
    "\n",
    "# Grade\n",
    "- 2 quizzes @10%\n",
    "- midterm 30%\n",
    "- selected hw problems 10%\n",
    "- project 40%\n",
    "    - report \n",
    "    - presentation\n",
    "    \n",
    "# Reading References\n",
    "1. Grimmett, G. and Stirzaker, D (2001)\n",
    "2. Insua, D.R., Ruggeri, F. & Wiper, M.P. (2012)\n",
    "3. Karlin, S. & Taylor, H.M. (1974) (Theory taken mostly from this)\n",
    "4. Ross, S.M. (1996)\n",
    "5. Guttorp, P. (1995)\n",
    "6. Zucchini, W. & Macdonald, I.L. (2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of Stochastic Process (SP)\n",
    "\n",
    "Consider a probability space ($\\Omega,\\F,\\P$) , where $\\omega$ is the sample space of the experiments. Let there be an index set $T$ and a state space $S$. A stochastic process is a collection \n",
    "\n",
    "$$ X =  \\bc{X(\\omega,t): \\omega\\in\\Omega, t\\in T} $$ \n",
    "\n",
    "such that \n",
    "1. for any $n$ and any set of index points $t_i\\in T, i=1,...,n$, $(X_t,...,X_{t_n})$, is an $n$-dim random variable defined on the prob. space ($\\Omega,\\F,\\P$) and taking values in $S^n=S\\times...\\times S$.\n",
    "2. For any fixed $\\omega \\in \\Omega$, $X_\\omega(\\cdot) = X(\\omega,\\cdot): T\\rightarrow S$ is a function defined on $T$ and taking values in $S$, referenced to as a sample path  of the stoc. proc.\n",
    "\n",
    "**Note that SP are distributions over functions.**\n",
    "\n",
    "Basically, SP can be viewed as either a collection of RV's $\\bc{X_t:t\\in T}$, or a collection of random functions $\\bc{X_\\omega: \\omega \\in \\Omega}$, depending on the nature of $T$ and $S$. (i.e. discrete-discrete, cont-disc, disc-cont, cont-cont).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n",
    "$(X_1,...,X_n) \\iid (\\Omega,\\F,\\P)$\n",
    "\n",
    "$X(n,\\omega) = X_n(\\omega)$\n",
    "\n",
    "$X = \\bc{X(n,\\omega): n\\in \\mathcal{N}, \\omega\\in \\Omega}$\n",
    "\n",
    "$X_i \\iid Pois(\\lambda)$, then discrete-time, discrete-space.\n",
    "\n",
    "$X_i \\iid \\N(\\mu,\\sigma^2)$, $T=\\mathcal{N}, S=\\mathcal{R}$ (discrete-time, cont-space (normal rv))\n",
    "\n",
    "# Random Walk\n",
    "This SP is a random walk:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(X_i=1)  &= \\pi \\\\\n",
    "P(X_i=-1) &= 1-\\pi \\\\\n",
    "S(n,\\omega) = S_n(\\omega) &= \\suml X_i(\\omega) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "--- \n",
    "\n",
    "Let $z$ be a RV.\n",
    "\n",
    "$P(Z=1)=P(Z=-1) = 1/2$\n",
    "\n",
    "$X(t,\\omega) = X_t(\\omega) = Z(\\omega) \\sin(t)$, for all $t\\ge 0$ cont-time, cont-space.\n",
    "\n",
    "$T=\\mathbb{R}^+, S = \\bc{\\sin t:t>0} \\cup \\bc{-\\sin t:T>0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any SP, we are interested in the distributional properties of $X_t(\\cdot)$. In this regard, we will define the finite dimensional distribution of a SP by looking at the joint distribution of the random vector \n",
    "$F_{t_1,...,t_n}(x_1,...,x_n) = P(X_{t_1} \\le x_1, ...,  X_{t_n} \\le x_n)$.\n",
    "\n",
    "**Q1: Suppose we know the finite dimensional distribution of a stochastic process, is it possible to specify the SP uniquely?** (No)\n",
    "\n",
    "**Q2: Suppose a finite dimensional distr. is provided and specified for every ($X_{t_1},...,X_{t_n}$) for all $t_1,...,t_n$ and for all $n$, does there exist a SP whose finite dim. distr is the one we specified?** (yes, with additional conditions)\n",
    "\n",
    "***\n",
    "\n",
    "Suppose $\\bc{X_t: t\\in T}$, $\\bc{Y_t: t\\in T}$ are two stochastic processes defined on the same $(\\Omega,\\F,\\P)$. \n",
    "We say that $Y$ is a version of $X$ if for every $t\\in T$, we have \n",
    "\n",
    "$$ P(X_t=Y_t) =P(\\bc{\\omega\\in\\Omega: X_t(\\omega) = Y_t(\\omega)}) =1 $$.\n",
    "\n",
    "We say that $X$ and $Y$ are indistinguishable (stronger) if \n",
    "\n",
    "$$ P(X_t=Y_t, \\forall t\\in T) = P(\\bc{\\omega\\in\\Omega: X_t(\\omega) = Y_t(\\omega), \\forall t\\in T}) = 1$$\n",
    "\n",
    "***\n",
    "\n",
    "$Z \\sim N(0,1)$\n",
    "\n",
    "$X_t = 0$\n",
    "\n",
    "$Y_t = 0$ if $t \\ne \\abs{Z}$, and 1 otherwise.\n",
    "\n",
    "$P(X_t\\ne Y_t) = P(\\abs{Z}=t) = 0$. $P(X_t=Y_t, t\\ge 0) = 0$.\n",
    "\n",
    "$Y$ is a version of $X$ and both $X$ and $Y$ have right-cont. sample paths then $X$ and $Y$ are indisinguishable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Given specification of a finite dim. distribution $F_{t_1,...,t_n}(x_1,...,x_n)$ ** for every $n \\ge 1$, and for any $t_1,...,t_n \\in T$, does it correspond to a finite dim. distribution (fdd) of a SP?\n",
    "\n",
    "## Kolmogorov Consistency Conditions\n",
    "If the finite dim. distr.  $F_{t_1,...,t_n}(x_1,...,x_n)$ satisfies\n",
    "\n",
    "1. $F_{t_1,...,t_n,t_{n+1}}(x_1,...,x_n,x_{n+1}) \\rightarrow F_{t_1,...,t_n}(x_1,...,x_n)$  as $x_{n+1} \\rightarrow \\infty$\n",
    "2. For all $n$, $x=(x_1,....,x_n)$, $t=(t_1,...,t_n)$, any permutation $\\pi = (\\pi(1),...,\\pi(n))$ of $\\bc{1,...,n}$, $F_{\\pi_t}(\\pi_x)=F_t(x)$ where $\\pi_x = (x_{\\pi_1},...,x_{\\pi_n})$ and   $\\pi_t = (t_{\\pi_1},...,t_{\\pi_n})$, \n",
    "\n",
    "then there exists a prob. space ($\\Omega,\\F,\\P$) and a collection $x=\\bc{x_t:t\\in T}$ of random variables defined on ($\\Omega,\\F,\\P$) s.t. $F_t$ is the fdd of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Important thing about a SP \n",
    "- we need to study properties of the sample path.\n",
    "  - for any $\\omega\\in\\Omega$, sample path $X_\\omega(t)$ is a function of the index set T $\\bc{X_\\omega(t):t\\in T}$ for a fixed $\\omega$.\n",
    "- A SP is used to assign prior distributions on an unknown function $\\mu(t)$. Typically, we make an assumpltion of the smoothness (differentiability) of the unknown function. Therefore, it is important to know the smoothness of the SP sample paths which are going to be  used as a prior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SP is cont. if for every $\\omega \\in \\Omega$, $X_w(t)$ as a function of $t$ (ie. the sample path) is cont. \n",
    "And more generally, a SP is $\\alpha$-Holder continuous if \n",
    "$ \\abs{X_\\omega(t) - X_\\omega(s)} \\le c\\abs{t-s}^\\alpha $ for all $t, s\\in T$ and for all $\\omega$ for some $c$.\n",
    "\n",
    "If  $\\alpha=1$, then $X_\\omega(t)$ is Lipschitz function.\n",
    "If  $\\alpha>1 \\Rightarrow (X_\\omega(t)-X_\\omega(s))/(t-s) \\le c\\abs{t-s}^{\\alpha-1}$ ... didn't finish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean function of a SP\n",
    "$\\mu(t) = \\E\\bk{X_t}$ if $t_i,t_j \\in T$, the autocovariance fn. of a SP is given by \n",
    "$C(t_i,t_j) = Cov(X_{t_i},X_{t_j})$ and the autocorrelation is Corr($X_{t_i},X_{t_j}$).\n",
    "\n",
    "An important property of the covariance function is that it is a non-negative definite function.\n",
    "\n",
    "**non-negative definite Matrix: **If $A_{n\\times n}$ is a non-negative definite matrix, then for any $(z_1,...,z_n)'=z$, $z'Az \\ge 0$.\n",
    "\n",
    "**non-negative definite function: ** $c(\\cdot,\\cdot)$ is a non-negative definite fn, if for any $n\\ge 1$ and $t_1,...,t_n$, $z'Cz \\ge 0$ where $C_{ij} = c(t_i,t_j)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance fn of a SP is a non-negative definite fn. \n",
    "Take $z_1,...,z_n$, $t_1,...,t_n \\in T$. \n",
    "\n",
    "$\\suml\\sum_{j=1}^n z_i z_j Cov(X_{t_i},X_{t_j}) = Var(\\suml z_i X_{t_i})$ which is non-negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SP is a white noise process if Cov($X_{t_i},X_{t_j}$) =0 for all $t_i\\ne t_j$.\n",
    "\n",
    "Also, a SP $X$ is a process with uncorrelated increments if for any  $t_i < t_j < t_k < t_l \\in T$, COV($X_{t_j}-X_{t_i}, X_{t_l}-X_{t_k}$) = 0.\n",
    "\n",
    "Two SP $X,Y$ defined on the same prob. space and with the same index set are uncorrelated if the cross-covariance fn \n",
    "$$C_{xy}(t_i,t_j) = Cov(X_{t_i},X_{t_j})= 0, \\forall t_i,t_j \\in T$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some of the simplifying assumptions to study SP better. The most important of them is the stationarity assumption. Theory and methods of SP are considerably simplified under the stationarity assumption. \n",
    "\n",
    "## Strong stationarity \n",
    "A SP $X$ is strongly stationary if its finite dimensional distributions are invariant under time shift. That is for any finite $n$, for any $t_0$ and for all $t_1,...,t_n \\in T$, $(x_{t_1},...,x_{t_n})$ and $(x_{t_1+t_0},...,x_{t_n+t_0})$ have the same distribution. \n",
    "\n",
    "\n",
    "## Weak Stationarity\n",
    "A SP $X$ is called weakly stationary if $\\forall t\\in T$, $\\E\\bk{X_t}=\\mu$ and for all $t_i,t_j \\in T$, COV($X_{t_i},X_{t_j}$) = $c(t_i-t_j)$ a fn of $t_i-t_j$ only.\n",
    "\n",
    "\n",
    "SS implies WS, WS not neccessarily imply SS, except in GP.\n",
    "\n",
    "\n",
    "From the Fourier analysis, any fn, $f: R \\rightarrow Q$ with periodicity and continuity has a unique Fourier expansion, $f(x) = a_0/2 + \\sum_{n=1}^\\infty a_n\\cos(nx) + b_n \\sin(nx)$  which expresses $f$ as a sum of ranging proportions of regular  oscillations. In some sense, weak stationarity processes are similar to periodic fn since their autocov fns are invariant under time shifts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral theorem for autocov fn.\n",
    "\n",
    "Consider a cont. time WS SP $X={X_t:t\\in\\mathbb R}$ with a strictly positive variance. If the autocov fn. $r(t)$ of $X$ is cont. at $t=0$, then there exists a distr fn. $F$ s.t. $r(t) = \\int_{-\\infty}^\\infty \\exp(itu) dF(u)$.\n",
    "\n",
    "If $F$ is the distribution fn. for a cont. RV, with density $f$, then inverse fourier transformation tells us that \n",
    "$$f(u) = \\frac{1}{2\\pi} \\int_{-\\infty}^\\infty \\exp(-itu) \\mu(t) dt$$ where $f$ is differentiable at $x$. (this f is known as the spectral density, which is the inverse Fourier transform of $\\mu$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $T = \\mathbb Z$, $X = \\bc{X_n: n\\in \\mathbb Z}$. \n",
    "\n",
    "\\begin{split}\n",
    "r(n) &= \\int_{-\\infty}^\\infty \\exp(inu) dF(u) \\\\\n",
    "     &= \\int_{-\\infty}^\\infty \\exp(in(u+2\\pi s)) dF(u), \\text{ where $s$ is any integer} \\\\\n",
    "\\end{split}\n",
    "\n",
    "So, $r(u) = \\int_{-\\pi}^\\pi\\exp(inu) dF(u)$. And spectral density comes from the inverse Fourier trans of $r(u)$. Hence, $f(u) = \\frac{1}{2\\pi} \\sum_{n=-\\infty}^\\infty \\exp(-inu)r(n)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of convergence of seq. of r.v. converge to a r.v X, \n",
    "1. convergence in probability:\n",
    "2. convergence in distribution:\n",
    "3. Mean-squared conv.:\n",
    "4. Almost-sure conv.: $X_n(\\omega)\\rightarrow X(\\omega), \\forall \\omega\\in\\Omega$\n",
    "    \n",
    "# Weak Law of Large Numbers (WLLN)\n",
    "$X1,...$ are iid rv with $\\E\\bk{X_i}=\\mu$ and Var($X_i=\\sigma^2<\\infty$) then $\\frac{1}{n}\\suml X_i \\rightarrow \\mu$ in probability.\n",
    "\n",
    "# Kolmogorov LLN\n",
    "$X_1,...$ are independent RV with $\\E\\bk{X_i}=0$ and $\\E\\bk{X_i^2} < \\infty$, $\\sum_i^\\infty \\frac{1}{i^2}\\E\\bk{X_i^2} < \\infty$ then $\\frac{1}{n}\\suml X_i \\rightarrow 0$ almost surely.\n",
    "\n",
    "# Ergodic Thm. for Weakly Stationary SP\n",
    "If $X = \\bc{X_j:j\\ge 1}$ is a WS SP, then there exists a random variable $Y$ such that $\\E\\bk{Y}=\\E\\bk{X_1}$ and\n",
    "$\\frac{1}{n}\\suml X_i \\rightarrow Y$ in mean square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of important SPs\n",
    "\n",
    "## Example 1 (Brownian Motion)\n",
    "Suppose there is a collection of RV's $\\bc{B_s: s\\ge 0}$, having a number of prroperties as following:\n",
    "1. $B_0=0$ (convention, the origin)\n",
    "2. $0\\le s<t<\\infty$,  $B_t-B_s\\sim \\N(0,t-s)$.\n",
    "3. $0\\le s<t<\\infty$,  $B_t-B_s$ is independent of $B_s$.\n",
    "4. The function $t\\rightarrow B_t$ is a continuous function.\n",
    "\n",
    "Condition 3. can be replaced by the following condition:\n",
    "- given $t_1 < t_2 < t_3 < t_4$, $B_{t_4}-B_{t_3}$ is independent of $B_{t_2}-B_{t_1}$.\n",
    "\n",
    "\n",
    "Einstein showed that the Brownian motion is the solution to the heat equation.\n",
    "\n",
    "\n",
    "Let $t_1,...,t_n\\in\\mathbb{R}$ , for any $n$,\n",
    "\\begin{split}\n",
    "\\begin{pmatrix} B_{t_1}\\\\ ... \\\\ B_{t_n} \\\\\\end{pmatrix} \\sim \\N(0,\\Sigma), \\text{ with } \\Sigma_{i,j}=\\min\\bc{t_i,t_j}\n",
    "\\end{split}\n",
    "\n",
    "So, any finite dimensional distribution is Gaussian. Note that it is easy to get the distribution of any linear combo given the multivariate distribution.\n",
    "\n",
    "Brownian motion is a special case of the GP. The sample paths for a Brownian motion are not differentiable, Einstein proved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "\n",
    "A GP is a SP for which any finite dimensional distribution is Normal, i.e. $\\bc{X_t:t\\in\\mathbb{R}}$ is a GP if \n",
    "for any $t_1,...,t_n$, $n\\in \\mathbb N$, \n",
    "\\begin{pmatrix} X_{t_1}\\\\ ... \\\\ X_{t_n} \\\\\\end{pmatrix} follorws a multivariate Normal density.\n",
    "\n",
    "## WEakLy Stationary GP\n",
    "\n",
    "A WSGP is determined by its mean and covariance kernel. Kernel is $c(t)=cov(x_s,x_{s+t})$. Therefore, the finite dim. distr. of a GP with a specified cov. kernel $c(t)$ is given by \n",
    "\\begin{split}\n",
    "\\begin{pmatrix} X_{t_1}\\\\ ... \\\\ X_{t_n} \\\\\\end{pmatrix} \\sim \\N(\\mu,\\Sigma), \\text{ with } \\Sigma_{i,j}=c(t_i-t_j)\n",
    "\\end{split}\n",
    "\n",
    "Common covariance functions\n",
    "1. modified Bessel function of the 2nd kind\n",
    "    - has 3 params, $\\nu,\\phi,\\sigma^2$. \n",
    "    - note that $c(0)=\\sigma^2$. so $\\sigma^2 = var(X_t)$.\n",
    "    - cov($x_s,x_{s+t}$) increases if $\\phi$ decreases. So $\\phi$ controls the correlation of the SP.\n",
    "    - $\\nu$ controls the smoothness of the SP. (aka the differentiability) In fact, Michael Stein showed that the sample paths of a GP with the above kernel is $\\ceil{\\nu-1}$ times differentiable.\n",
    "    \n",
    "Cases for $\\nu$\n",
    "1. If $\\nu=1/2$, $c(t)=\\sigma^2\\exp(-\\phi t)$: exponential corr. fn (statisticians use this)\n",
    "2. If $\\nu=\\infty$, $c(t)=\\sigma^2\\exp(-\\phi t^2)$: Gaussian corr. fn (machine learners use this because it produces better predictions, but the cov. matrices are not invertable, so they don't use it.)\n",
    "3. If $\\nu=3/2$, $c(t)=$ nasty: once differentiable.\n",
    "\n",
    "Sample paths are nowhere differentiable  in 1. In 2, sample paths are infintely differentiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- splines: [David Rupert Semi-parametric modeling]( https://books.google.com/books/about/Semiparametric_Regression.html?id=Y4uEvXFP2voC)\n",
    "    - splines with time series for LLNL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
